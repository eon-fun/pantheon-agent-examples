import asyncio
import os
from urllib.parse import urljoin

import aiohttp
from aiogram import Bot, Dispatcher
from aiogram.filters import Command
from aiogram.types import Message
from aiohttp import ClientConnectorError
from bs4 import BeautifulSoup
from database.redis.redis_client import RedisDB
from services.ai_connectors.openai_client import send_openai_request
from tenacity import retry, stop_after_attempt, wait_fixed

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Redis
db = RedisDB()
PROCESSED_LINKS_KEY = "processed_articles"
NEWS_SITES_KEY = "news_sites"
TWITTER_ACCOUNTS_KEY = "twitter_accounts"
PROCESSED_TWEETS_KEY = "processed_tweets"

# Telegram –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHANNEL_ID = os.getenv("TELEGRAM_CHANNEL_ID", "@your_channel")

TWITTER_BASIC_BEARER_TOKEN = os.getenv("TWITTER_BASIC_BEARER_TOKEN")
GROK_API_URL = os.getenv("GROK_API_URL", "https://api.x.ai/v1/chat/completions")
GROK_API_KEY = os.getenv("GROK_API_KEY")

PROMPT = (
    "You are a Telegram post author for a cryptocurrency news channel. "
    "Write concise and engaging posts in English with proper Markdown formatting. "
    "But dont use ###."
)
"Extract the most important points from the input text, include a short "
"headline with emojis, highlight key terms or names using bold formatting, "
"and use italic for emphasis. End the post with a simple, engaging closing "
"line like 'Stay tuned for more updates! üöÄüìà' or similar. And some hashtags."

GROK_PROMPT = "You need to search for the hottest tweets and news for a given query"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞
bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher()

# –û—á–µ—Ä–µ–¥—å —Å–æ–æ–±—â–µ–Ω–∏–π
message_queue = asyncio.Queue()


# 1. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –æ—á–µ—Ä–µ–¥—å
async def add_to_queue(text: str):
    await message_queue.put(text)
    print(f"üìù –°–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –æ—á–µ—Ä–µ–¥—å: {text[:50]}...")


@retry(stop=stop_after_attempt(5), wait=wait_fixed(2))
async def send_message_with_retry(chat_id, text):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏."""
    try:
        async with aiohttp.ClientSession(connector=aiohttp.TCPConnector(ssl=False)) as session:
            await bot.send_message(chat_id=chat_id, text=text, parse_mode="Markdown")
    except ClientConnectorError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å Telegram API: {e}")
        raise  # –ü–æ–≤—Ç–æ—Ä—è–µ–º –ø–æ–ø—ã—Ç–∫—É


# 2. –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—á–µ—Ä–µ–¥–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
async def message_sender():
    print("üöÄ –ó–∞–ø—É—â–µ–Ω –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—á–µ—Ä–µ–¥–∏ —Å–æ–æ–±—â–µ–Ω–∏–π.")
    while True:
        message = await message_queue.get()
        try:
            print(f"üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è: {message[:50]}...")
            await send_message_with_retry(chat_id=TELEGRAM_CHANNEL_ID, text=message)
            await asyncio.sleep(30)  # –ü–∞—É–∑–∞ –≤ –æ—á–µ—Ä–µ–¥–∏ –º–µ–∂–¥—É –æ—Ç–ø—Ä–∞–≤–∫–æ–π –ø–æ—Å—Ç–æ–≤ –≤ —Ç–µ–ª–µ–≥—Ä–∞–º–º
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        finally:
            message_queue.task_done()


# 3. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Grok AI –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–≤–∏—Ç–æ–≤
async def fetch_tweets_from_grok(query: str):
    headers = {
        "Authorization": f"Bearer {GROK_API_KEY}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": "grok-beta",
        "messages": [{"role": "system", "content": GROK_PROMPT}, {"role": "user", "content": query}],
    }

    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(GROK_API_URL, headers=headers, json=payload) as response:
                if response.status != 200:
                    print(f"\u274c –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Grok: –°—Ç–∞—Ç—É—Å {response.status}")
                    response_text = await response.text()
                    print(f"–û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞: {response_text}")
                    return []

                data = await response.json()
                print(f"\u2705 –û—Ç–≤–µ—Ç –æ—Ç Grok: {data}")

                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ç–≤–∏—Ç–æ–≤
                choices = data.get("choices", [])
                tweets = []
                for choice in choices:
                    message = choice.get("message", {})
                    content = message.get("content")
                    if content:
                        tweets.append(content)

                return tweets

    except Exception as e:
        print(f"\u274c –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Grok: {e}")
        return []


# 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ GPT
async def rewrite_text(text):
    messages = [{"role": "system", "content": PROMPT}, {"role": "user", "content": text}]
    try:
        ai_response = await send_openai_request(messages)
        return ai_response.strip()
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}"


@dp.message(Command("find_in_grok"))
async def find_in_grok(message: Message):
    query = message.text[len("/find_in_grok ") :].strip()
    if not query:
        await message.reply("‚ö†Ô∏è –£–∫–∞–∂–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ Grok.")
        return

    print(f"üîç –ü–æ–∏—Å–∫ —Ç–≤–∏—Ç–æ–≤ –≤ Grok –ø–æ –∑–∞–ø—Ä–æ—Å—É: {query}")
    tweets = await fetch_tweets_from_grok(query)

    if not tweets:
        await message.reply("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ç–≤–∏—Ç—ã –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É.")
        return

    for tweet in tweets:
        rewritten = await rewrite_text(tweet)
        await add_to_queue(rewritten)
    await message.reply("‚úÖ –¢–≤–∏—Ç—ã –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –æ—á–µ—Ä–µ–¥—å –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏.")


# 3. –°–±–æ—Ä —Å—Å—ã–ª–æ–∫ —Å —Å–∞–π—Ç–æ–≤
async def fetch_latest_articles(base_url):
    headers = {"User-Agent": "Mozilla/5.0"}
    keywords = ["news", "article", "post", "blog", "story"]

    try:
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=20)) as session:
            async with session.get(base_url, headers=headers) as response:
                response.raise_for_status()
                html = await response.text()
                soup = BeautifulSoup(html, "html.parser")
                article_links = {
                    urljoin(base_url, link["href"])
                    for link in soup.find_all("a", href=True)
                    if any(keyword in link["href"].lower() for keyword in keywords)
                }
                print(f"üîó –ù–∞–π–¥–µ–Ω–æ {len(article_links)} —Å—Ç–∞—Ç–µ–π –Ω–∞ {base_url}")
                return article_links
    except aiohttp.ClientConnectorError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å {base_url}: {e}")
    except asyncio.TimeoutError:
        print(f"‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ {base_url}")
    except Exception as e:
        print(f"‚ùå –î—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–µ–π —Å {base_url}: {e}")
    return set()


async def scrape_site(url):
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=20)) as session:
            async with session.get(url, headers=headers) as response:
                response.raise_for_status()
                soup = BeautifulSoup(await response.text(), "html.parser")
                paragraphs = soup.find_all("p")
                return " ".join([p.get_text() for p in paragraphs])
    except aiohttp.ClientConnectorError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {url}: {e}")
    except asyncio.TimeoutError:
        print(f"‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {url}")
    except Exception as e:
        print(f"‚ùå –î—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {url}: {e}")
    return None


# 5. –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–≤–∏—Ç–æ–≤ —Å –∞–∫–∫–∞—É–Ω—Ç–æ–≤
async def fetch_tweets_from_accounts():
    accounts = db.get_set(TWITTER_ACCOUNTS_KEY)
    processed_tweets = set(db.get_set(PROCESSED_TWEETS_KEY))
    all_tweets = []

    BEARER_TOKEN = TWITTER_BASIC_BEARER_TOKEN
    headers = {"Authorization": f"Bearer {BEARER_TOKEN}"}

    for account in accounts:
        try:
            print(f"üîç –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–≤–∏—Ç–æ–≤ –¥–ª—è @{account}")
            async with aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=30),
                connector=aiohttp.TCPConnector(ssl=False),  # –û—Ç–∫–ª—é—á–∞–µ–º SSL-–≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—é
            ) as session:
                # –®–∞–≥ 1: –ü–æ–ª—É—á–∞–µ–º user_id –ø–æ username
                user_info_url = f"https://api.twitter.com/2/users/by/username/{account}"
                async with session.get(user_info_url, headers=headers) as resp:
                    if resp.status != 200:
                        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å user_id –¥–ª—è @{account}. –°—Ç–∞—Ç—É—Å: {resp.status}")
                        continue

                    user_data = await resp.json()
                    if "data" not in user_data:
                        print(f"‚ùå –ê–∫–∫–∞—É–Ω—Ç @{account} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
                        continue

                    user_id = user_data["data"]["id"]

                # –®–∞–≥ 2: –ü–æ–ª—É—á–∞–µ–º —Ç–≤–∏—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                tweets_url = f"https://api.twitter.com/2/users/{user_id}/tweets"
                params = {"max_results": 5}  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–≤–∏—Ç–æ–≤
                async with session.get(tweets_url, headers=headers, params=params) as resp:
                    if resp.status != 200:
                        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–≤–∏—Ç—ã –¥–ª—è @{account}. –°—Ç–∞—Ç—É—Å: {resp.status}")
                        continue

                    tweets_data = await resp.json()
                    if "data" not in tweets_data:
                        print(f"‚ùå –¢–≤–∏—Ç—ã –¥–ª—è @{account} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
                        continue

                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–æ–≤—ã–µ —Ç–≤–∏—Ç—ã
                    for tweet in tweets_data.get("data", []):
                        if tweet["id"] not in processed_tweets:
                            db.add_to_set(PROCESSED_TWEETS_KEY, tweet["id"])
                            all_tweets.append(tweet["text"])
                            print(f"‚úÖ –ù–æ–≤—ã–π —Ç–≤–∏—Ç: {tweet['text'][:50]}...")

        except aiohttp.ClientConnectorError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å Twitter –¥–ª—è @{account}: {e}")
        except asyncio.TimeoutError:
            print(f"‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ç–≤–∏—Ç–æ–≤ –¥–ª—è @{account}")
        except Exception as e:
            print(f"‚ùå –î—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ç–≤–∏—Ç–æ–≤ –¥–ª—è @{account}: {e}")

    return all_tweets


# 7. –û—Å–Ω–æ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∞—Ç–µ–π –∏ —Ç–≤–∏—Ç–æ–≤
async def process_new_articles():
    news_sites = db.get_set(NEWS_SITES_KEY)
    processed_links = set(db.get_set(PROCESSED_LINKS_KEY))

    for site in news_sites:
        new_links = await fetch_latest_articles(site)
        for link in new_links - processed_links:
            text = await scrape_site(link)
            if text:
                rewritten = await rewrite_text(text)
                await add_to_queue(rewritten)
                db.add_to_set(PROCESSED_LINKS_KEY, link)


async def process_twitter_posts():
    tweets = await fetch_tweets_from_accounts()
    for tweet in tweets:
        rewritten = await rewrite_text(tweet)
        await add_to_queue(rewritten)


# 8. –ö–æ–º–∞–Ω–¥—ã –±–æ—Ç–∞
@dp.message(Command("add_links"))
async def add_links(message: Message):
    links = message.text.split()[1:]
    for link in links:
        db.add_to_set(NEWS_SITES_KEY, link)
    await message.reply("‚úÖ –°–∞–π—Ç—ã –¥–æ–±–∞–≤–ª–µ–Ω—ã!")


@dp.message(Command("add_x_account"))
async def add_twitter_account(message: Message):
    accounts = message.text.split()[1:]
    for account in accounts:
        db.add_to_set(TWITTER_ACCOUNTS_KEY, account.strip("@"))
    await message.reply("‚úÖ Twitter –∞–∫–∫–∞—É–Ω—Ç—ã –¥–æ–±–∞–≤–ª–µ–Ω—ã!")


# 9. –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –∑–∞–¥–∞—á–∞
async def periodic_task():
    while True:
        print("üîé –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç–µ–π –∏ —Ç–≤–∏—Ç–æ–≤...")
        await process_new_articles()
        await process_twitter_posts()
        await asyncio.sleep(
            10
        )  # –ü–∞—É–∑–∞ –≤ –ø–æ–∏—Å–∫–µ —Å—Ç–∞—Ç—å–µ–π –∏ —Ç–≤–∏—Ç–æ–≤. –†–µ–∫–æ–º–µ–Ω–¥—É—é –º–∏–Ω–∏–º—É–º 1 —á–∞—Å, –ø–æ–∫–∞ –≤ —Ç–µ—Å—Ç —Ä–µ–∂–∏–º–µ - 10 —Å–µ–∫


# 10. –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
async def main():
    asyncio.create_task(message_sender())  # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—á–µ—Ä–µ–¥–∏
    asyncio.create_task(periodic_task())  # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())
